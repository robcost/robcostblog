---
title: We Need to Build
date: 2026-02-25
authors:
  - name: robcost
    link: https://github.com/robcost
tags:
  - AI
  - Australia
excludeSearch: false
---

Give me a billion dollars, 20 smart and well-paid people, access to GPUs and cloud resources, and twelve months. I'd give it a 1% chance of being a worthwhile investment, but it could be the Snowy Hydro of the 21st century for Australia.

I've watched the discourse about AI in Australia for a while now, the hand-wringing about being "left behind," the earnest policy papers, the endless conferences. And I keep arriving at the same conclusion: this isn't an AI problem. It's a risk problem. We've lost the appetite for doing big things for the benefit of the nation.

## The risk problem

Australia is not culturally or politically set up to take the kind of bets that create new industries. We're not alone in this — most western nations outside the US seem incapable of incubating new businesses and fostering applied development of technology at the scale required. We all follow the same playbook: funnel money into academic-led research and development, a path that takes years to bear fruit, a path that in the current era of AI is never going to deliver returns on the order seen from America's startup ecosystem.

Then we talk. We talk about regulation, governance, safety — all things that, however well-intentioned, serve primarily to control and slow down development. Globally, the hard part of the current generative AI wave is behind us. There are established patterns for developing and commercialising AI models. We don't need to research the fundamentals — that work is done. We don't need to pre-emptively apply controls sequentially in ways that block adoption. We need to run governance in parallel with building, not as a prerequisite to it.

Stewart Brand had a useful concept for this: [pace layers](https://jods.mitpress.mit.edu/pub/issue3-brand). First developed in *How Buildings Learn* (1994) and later expanded in *The Clock of the Long Now* (1999), the idea is that different parts of a system move at different speeds. Technology moves at the fastest layer. Governance, regulation, and institutional frameworks move at the slowest. When you insist that the slow layers must be fully resolved before the fast layers can proceed, you guarantee you'll never catch up. We won't finish writing our 500-page governance framework just in time for the final release of "the AI." There is no final release. The machine is constantly changing shape, changing capability, changing economically. We need to get on with it.

## The digital resource curse

Here's where it gets uncomfortable for a country built on mining and university education. Australia already knows what happens when you're rich in export commodities — it hollows out your other industries. Economists call it [Dutch Disease](https://en.wikipedia.org/wiki/Dutch_disease), and Australia is a [textbook case](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8462.2012.00685.x). Iron ore, coal, gas — we've ridden successive mining booms while watching manufacturing and other tradeable sectors wither under an inflated exchange rate and a talent pool drained toward the mines.

There's a digital version emerging, and we're sleepwalking right into it. We export raw data and import refined AI products. We rent tools built elsewhere. The value is captured offshore.

[Sue Keay made this point sharply this week](https://www.linkedin.com/pulse/australias-ai-tide-finally-turning-sue-keay-t1trc), echoing Dr Andrew Charlton's speech: "If the tools are owned elsewhere, and we simply rent them, the dividends flow offshore." That's not abstract economics. That's the structural reality of a country that chooses to consume rather than create. We become a digital resource colony, and the resource flowing out this time isn't iron ore — it's the value extracted from our data, our industries, our problems.

We don't have to be the perpetual consumer country, forever importing and never building. We can generate our own technology and build national wealth along the way. There have been flashes of this in the past, but we aren't moving fast enough to join the current race.

## Amara's Law and the cost of waiting

There's a particular strain of Australian AI commentary that drives me up the wall. It goes something like: "everyone is overhyping AI, the productivity gains haven't materialised, so let's slow down and think carefully before we act." [John H. Howard's recent piece in Pearls and Irritations](https://johnmenadue.com/post/2026/02/why-we-need-to-stop-predicting-ai-and-start-thinking-about-it/) is a good example — thoughtful, measured, and ultimately an argument for doing less while we figure things out.

Here's my problem with it. He's half right, and the half he is right about is the unimportant half.

Amara's Law says we tend to overestimate the effect of a technology in the short run and underestimate it in the long run. The "let's slow down" crowd is correctly identifying the short-term overestimation. Yes, the consulting firm projections are noisy. Yes, most enterprise AI pilots fail to deliver measurable returns. Yes, the February 2026 market correction exposed the gap between AI infrastructure spending and demonstrated revenue.

But Amara's Law has a second half, and it's the dangerous part. The long-run impact will be bigger than anyone currently expects. Which means the cost of waiting — of spending years building governance frameworks and "complementary conditions" — isn't neutral. It's compounding. Every year Australia spends in analysis mode is a year where the long-term gap widens, and the window for catching up gets smaller.

The commentariat diagnoses the Amara short-term overestimation correctly while completely ignoring the long-term underestimation that makes urgency essential. They write 1500 words about why everyone's predictions are wrong, then implicitly recommend the one course of action — waiting — that is catastrophic if the long-run impact is as large as history suggests it will be.

## Building through the uncertain period

Howard's article references the [Productivity Paradox](https://en.wikipedia.org/wiki/Productivity_paradox) — Robert Solow's observation that computers were everywhere except the productivity statistics. It's a good reference, but Howard draws exactly the wrong conclusion from it.

The paradox did eventually resolve. Erik Brynjolfsson's research showed that the productivity gains from IT arrived roughly 15 years after the investments were made, and they came when technology investment was paired with organisational change — new processes, new skills, new ways of working. The gains showed up most in sectors like retail, wholesale, and finance that committed to both the technology and the transformation around it.

Now, Howard would say this proves his point: you need "complementary conditions" before the technology delivers. And he's not wrong about the mechanism. But he's wrong about the timing. The companies and sectors that captured those delayed productivity gains didn't wait until the complementary conditions were perfectly in place before investing. They invested in the technology and the organisational transformation in parallel, through years of uncertain returns. The lag hypothesis tells us that returns come well after investment, which means you have to commit before the payoff is visible. That's not an argument for patience. It's the opposite — it's an argument for starting now, because the clock on that 15-year lag doesn't start ticking until you begin.

Australia's policy class is using the need for complementary investment as a reason to delay the primary investment. That's like refusing to plant a tree because you haven't built the fence around it yet.

## Jevons Paradox and what Australia should build

So what should we actually build? Frontier foundation models? Trying to out-compete the US and China on raw model scale would be like trying to out-mine BHP with a shovel.

But here's where an old economic paradox points to an enormous opportunity. Jevons Paradox, first observed in 1865 about coal consumption, says that as a resource becomes more efficient to use, total consumption goes up, not down. Make engines more fuel-efficient, and people drive more. Make compute more efficient, and people use more compute.

Sue Keay made the point that Australia produces world-class AI talent in exactly the areas the world currently needs: efficient algorithms, resource-constrained environments, systems designed for practical deployment. This is where Jevons gets interesting. If Australia builds genuinely efficient AI models — smaller, greener, less compute-hungry — the global demand for those models doesn't shrink. It explodes. Efficiency doesn't reduce the market. It expands it.

But this isn't only about small models. Australia should be building across the spectrum — foundation models, domain-specific models, and everything in between. The point isn't to hedge toward one end of the scale. It's to build, full stop. The efficient models are where we have a natural edge, but constraining our ambition to only that category would be making the same mistake the Productivity Commission made: assuming our role in the value chain should be modest.

As energy and compute costs become the binding constraint globally (and they will), the market for AI built with real-world deployment in mind becomes enormous. Health, energy, agriculture, defence, mining, construction, education — these aren't niche markets. They're the economy.

This is Clayton Christensen's Innovator's Dilemma applied to nations. The incumbents — the US and China — are building massive, expensive frontier models. The disruptive opportunity is in smaller, efficient, domain-specific models. Disruption theory says the incumbents will initially ignore this space because the margins look small compared to their core business. That's the gap. But disruption windows close, and they close fast.

## Comparative advantage is built, not found

The Productivity Commission's 2024 paper [*Making the most of the AI opportunity*](https://www.pc.gov.au/research/completed/making-the-most-of-the-ai-opportunity) suggested, in its section on "Australia's role in the AI value chain" (Paper 1, pp. 5–6), that Australia's position should be driven by "comparative advantage" and that "activist government 'sponsorship' of parts of the AI value chain is unlikely to yield ongoing productivity benefits." Essentially: buy off-the-shelf and focus on what we're already good at.

This fundamentally misunderstands how comparative advantage works in technology. Classical comparative advantage theory assumes static endowments — you have iron ore, they have semiconductors, everyone trades. But in technology, comparative advantage is created through investment, talent development, and ecosystem building.

Canada didn't have a "natural" comparative advantage in AI in 2017. They manufactured one through deliberate strategy and early investment via their Pan-Canadian AI Strategy, and they've seen the dividends in AI talent, research depth, and commercialisation pathways. Australia's comparative advantage in AI won't be discovered by economists — it'll be built by engineers, or it won't exist at all.

## Skin in the game

There's something that bothers me about who's shaping this debate. The people writing governance frameworks, advising on "complementary conditions," and urging caution have no skin in the game. Their careers don't depend on whether Australia captures AI value or not. They get paid whether we build or whether we study the question for another decade.

Nassim Taleb would have a field day with this. The technologists, founders, and engineers — the people who actually have something to lose — are overwhelmingly saying "we need to move faster." When the people with skin in the game are all saying one thing, and the people with nothing to lose are saying the opposite, you should probably listen to the former.

I'm not dismissing the value of thoughtful analysis. But there's a difference between analysis that informs action and analysis that substitutes for it. Australia has plenty of the latter.

## The talent doom loop

A lot of the discourse about AI revolves around its impact on jobs. Companies are already using AI as an excuse for layoffs, but have those companies really implemented AI at scale and seen the impact? Have they? The truth is no one has any clue what the long-term impacts will be. Everyone is guessing. Assuming history will simply repeat itself or that some neat pattern will apply is a bet against the sheer complexity and unpredictability of how these things play out.

But here's the impact I can see clearly, because I've watched it happen for 25 years: talent goes where the opportunities are. If Australia doesn't build, the best people leave. When the best people leave, the case for building looks weaker — "we don't have the talent." Which causes more people to leave. It's a self-reinforcing doom loop, and the only way to break it is to create the opportunities first, even before all the conditions are "ready."

Canada understood this. Their AI strategy was as much a talent retention play as a technology play. Australia is home to many great technologists, and too many of them are wasting away in roles that don't come close to letting them reach their full potential.

## The access problem

Access to funding, both government and private, is simply too hard. Our tax and legal systems aren't set up to support a risk-based sector like technology startups, especially in an era when things move this fast. We get bogged down in layer upon layer of policy, more processes to ensure everyone has a role to play. And while we carefully design the bureaucratic architecture, the technology itself is transforming underneath us.

AI platforms exhibit strong network effects — more users generate more data, which improves models, which attracts more users. This means the gap between leaders and followers doesn't close over time. It widens. Every year of delay isn't a linear cost. It's exponential. If Australia wants to really ride this wave, really build and become a net exporter of AI-based technology, then we can't wait for the unknowns to become known. By that time, every other nation will have accelerated past us. Many already have.

## Sovereignty isn't nationalism

This isn't about flag-waving. When your AI infrastructure is entirely controlled by foreign companies, you have genuine dependency risks. Pricing power sits with them. Your data is governed by their jurisdictions. Your critical systems rely on their uptime and their policy decisions.

We've already seen what happens when cloud providers change terms of service, when geopolitical tensions disrupt supply chains, when a single company's policy decision affects an entire downstream ecosystem. AI sovereignty isn't protectionism — it's the same logic as why countries maintain domestic food production and energy capacity. It's risk management at a national level.

Australia has real advantages here: renewable energy abundance, undersea connectivity, a strong research base, proximity to 4.8 billion people in the Asia-Pacific. But advantages only compound if matched with strategy. Without it, they're just nice facts for a consultant's slide deck.

## We need to build

I keep coming back to the same place. The capability exists. The talent exists. The opportunity exists. What's missing is the willingness to back it.

We need leaders unafraid to be ambitious for our future. We need to be comfortable with the possibility of failure, because the cost of not trying dwarfs the cost of trying and occasionally getting it wrong. We need to stop studying the wave and start riding it.

We need to build. If I had a billion dollars I'd do it.
